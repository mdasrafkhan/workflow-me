import { DataSource } from 'typeorm';
import { WorkflowExecutionsScheduleOptimization1700000000001 } from './src/database/migrations/WorkflowExecutionsScheduleOptimization';

async function runWorkflowOptimizationMigration() {
  console.log('üöÄ Starting workflow database optimization migration...');

  const dataSource = new DataSource({
    type: 'postgres',
    host: process.env.DB_HOST || 'localhost',
    port: parseInt(process.env.DB_PORT || '5432'),
    username: process.env.DB_USER || 'workflow_user',
    password: process.env.DB_PASSWORD || 'workflow_password',
    database: process.env.DB_NAME || 'workflow_db',
    entities: [],
    migrations: [WorkflowExecutionsScheduleOptimization1700000000001],
    synchronize: false,
    // Add connection pool settings for migration
    extra: {
      max: 5,
      min: 1,
      acquire: 10000,
      idle: 5000,
    },
  });

  try {
    await dataSource.initialize();
    console.log('‚úÖ Database connected');

    const migration = new WorkflowExecutionsScheduleOptimization1700000000001();
    await migration.up(dataSource.createQueryRunner());
    console.log('‚úÖ Database optimization migration completed successfully');

    await dataSource.destroy();
    console.log('‚úÖ Database connection closed');
    console.log('üéâ Ready for multi-pod deployment!');
  } catch (error) {
    console.error('‚ùå Migration failed:', error.message);
    if (error.message.includes('already exists')) {
      console.log('‚ÑπÔ∏è  Some indexes may already exist - this is normal');
      console.log('‚úÖ Migration completed with warnings');
    } else {
      console.error('‚ùå Fatal migration error:', error);
      process.exit(1);
    }
  }
}

runWorkflowOptimizationMigration();
